import cv2  # for camera vision task
from ultralytics import YOLO  # YOLOv8 model
import numpy as np  # used for numerical computing
import requests  # to send data to Node-RED
import base64  # to encode the frame as base64 for transmission
import datetime  # for timestamping the data
import json  # to handle the payload for Node-RED



# Load the pretrained YOLO model
model = YOLO(r'C:\Users\mdsya\Downloads\train40\train40\weights\best.pt')  # Path to the trained YOLO model

# Define the output file for logging
log_file = "C:\\Users\\mdsya\\OneDrive\\Desktop\\FinalOutput.txt"  # Set the path for the output log file

# Function to clear the log file
def clear_file(file):
    with open(file, 'w') as file:
        pass #opening the file in 'w' mode will clear its content
    
clear_file(log_file) #log file is cleared before starting

# IP camera URL (DroidCam if using phone or other IP camera URL)
ip_camera_url = 'http://192.168.1.101:4747/video'  # Replace with your IP camera's URL

# Open the IP camera stream
cap = cv2.VideoCapture(ip_camera_url)

if not cap.isOpened():
    print("Error: Unable to open the camera stream")
    exit()

# Node-RED endpoint URL (update this based on your setup)
node_red_url = "http://127.0.0.1:1880/human"  # Replace with your actual Node-RED URL

# Function to send data to Node-RED
def send_to_nodered(human_count, max_confidence, min_confidence, frame):
    # Encode the frame to base64
    _, buffer = cv2.imencode('.jpg', frame)
    img_base64 = base64.b64encode(buffer).decode('utf-8')  # Encode to base64 string

    max_confidence = float(max_confidence) if max_confidence != float('inf') else 0.0
    min_confidence = float(min_confidence) if min_confidence != float('inf') else 0.0
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # Construct the payload for Node-RED
    count_payload = {
        'Human': human_count,
        'MaxConfidence': max_confidence,
        'MinConfidence': min_confidence,
        'Image': img_base64,
        'Timestamp': timestamp # Add timestamp
    }

    # Send a POST request to Node-RED
    try:
        # Adjust timeout (set to 10 seconds for more time)
        response = requests.post(url=node_red_url, json=count_payload, timeout=10)
        
        # Check if the request was successful
        response.raise_for_status()  # Raise an error for bad responses (4xx, 5xx)
        print(f"Sent data to Node-RED: {response.status_code}")
    except requests.exceptions.Timeout:
        print("Timeout: Node-RED server did not respond.")
    except requests.exceptions.ConnectionError:
        print("Connection Error: Unable to reach Node-RED server.")
    except requests.exceptions.HTTPError as err:
        print(f"HTTP Error: {err}")
    except Exception as e:
        print(f"Error sending data to Node-RED: {e}")

        # Log the detection results into a text file
    with open(log_file, "a") as file:
        file.write(f"Timestamp: {timestamp}\n")
        file.write(f"Human: {human_count}\n")
        file.write(f"Max Confidence: {max_confidence:.2f}, Min Confidence: {min_confidence:.2f}\n")
        file.write("-" * 50 + "\n")  # Separator for better readability


# Process each frame from the camera
while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        print("Failed to capture frame")
        break

    print("Captured frame successfully")  # Debugging line

    # Perform inference on the current frame
    results = model(frame)  # Run inference on the current frame

    # Access the first result in the results list
    detections = results[0]  # results is a list; get the first detection object

    human_count = 0
    min_confidence = float('inf')
    max_confidence = 0

    # Check if there are any detections
    if detections.boxes is not None:
        # Extract the bounding boxes, confidences, and class IDs
        boxes = detections.boxes.xywh.cpu().numpy()  # Bounding box coordinates
        confidences = detections.boxes.conf.cpu().numpy()  # Confidence scores
        class_ids = detections.boxes.cls.cpu().numpy().astype(int)  # Class IDs
        labels = model.names  # Class names
        

        # Draw bounding boxes and labels
        for box, confidence, class_id in zip(boxes, confidences, class_ids):
            x, y, w, h = box
            labels[class_id] = "Human"
            label_name = labels[class_id]
            confidence_score = confidence

            # Count humans
            if label_name == 'Human':
                human_count += 1
      
            # Update max and min confidence scores
            max_confidence = max(max_confidence, confidence_score)
            min_confidence = min(min_confidence, confidence_score)

            # Calculate the top-left and bottom-right coordinates of the bounding box
            start_point = (int(x - w / 2), int(y - h / 2))
            end_point = (int(x + w / 2), int(y + h / 2))

            # Draw bounding box and label on the frame
            cv2.rectangle(frame, start_point, end_point, (0, 255, 0), 2)
            cv2.putText(
                frame,
                f"{label_name} ({confidence_score:.2f})",
                (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (36, 255, 12),
                2
            )

    # Send the detection data to Node-RED
    send_to_nodered(human_count, max_confidence, min_confidence, frame)

    # Display the annotated frame
    cv2.imshow("Human Ripeness Detection", frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()
