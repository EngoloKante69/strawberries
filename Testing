import cv2  # for camera vision task
from ultralytics import YOLO  # YOLOv8 model
import numpy as np  # used for numerical computing

# Load the pretrained YOLO model
model = YOLO('/home/melvin/Projects/strawberry_runs/train36/weights/best.pt')  # Path to the trained YOLO model

# IP camera URL (DroidCam if using phone or other IP camera URL)
ip_camera_url = "http://192.168.0.102:4747/video"  # Replace with your IP camera's URL

# Open the IP camera stream
cap = cv2.VideoCapture(ip_camera_url)

if not cap.isOpened():
    print("Error: Unable to open the camera stream")
    exit()

# Process each frame from the camera
while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        print("Failed to capture frame")
        break

    print("Captured frame successfully")  # Debugging line

    # Perform inference on the current frame
    results = model(frame)  # Run inference on the current frame

    # Access the first result in the results list
    detections = results[0]  # `results` is a list; get the first detection object

    # Check if there are any detections
    if detections.boxes is not None:
        # Extract the bounding boxes, confidences, and class IDs
        boxes = detections.boxes.xywh.cpu().numpy()  # Bounding box coordinates
        confidences = detections.boxes.conf.cpu().numpy()  # Confidence scores
        class_ids = detections.boxes.cls.cpu().numpy().astype(int)  # Class IDs
        labels = model.names  # Class names

        # Draw bounding boxes and labels
        for box, confidence, class_id in zip(boxes, confidences, class_ids):
            x, y, w, h = box
            label_name = labels[class_id]
            confidence_score = confidence

            # Calculate the top-left and bottom-right coordinates of the bounding box
            start_point = (int(x - w / 2), int(y - h / 2))
            end_point = (int(x + w / 2), int(y + h / 2))

            # Draw bounding box and label on the frame
            cv2.rectangle(frame, start_point, end_point, (0, 255, 0), 2)
            cv2.putText(
                frame,
                f"{label_name} ({confidence_score:.2f})",
                (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (36, 255, 12),
                2
            )

    # Display the annotated frame
    cv2.imshow("Strawberry Ripeness Detection", frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()
